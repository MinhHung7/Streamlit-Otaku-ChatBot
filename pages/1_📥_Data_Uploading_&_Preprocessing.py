import streamlit as st
import pandas as pd
import papermill as pm
import os
from datetime import datetime
import re

# Set the page title
st.set_page_config(page_title="Data Upload and Preprocessing", page_icon="üì•")

# Title of the page
st.title("Upload Your Anime Dataset")

# Instructions for the user
st.markdown("""
Please upload a CSV file containing anime data. The dataset will be processed and visualized in later steps. 

The file should contain relevant columns, such as anime title, genre, rating, and production studio.

### Allowed File Format:
- Only CSV files are allowed. 
""")

# Function to clear cache before running
def clear_cache():
    # For Streamlit versions 1.14 and later
    try:
        st.cache_resource.clear()
    except AttributeError:
        pass  # st.cache_data may not be available in older versions

# Call cache clearing function before uploading the file or processing
clear_cache()

# File uploader widget to upload a CSV file
uploaded_file = st.file_uploader("Choose a CSV file", type=["csv"])

# Check if a file is uploaded
if uploaded_file is not None:
    st.write(f"Uploaded file: {uploaded_file.name}")

    # Ensure the directory exists before saving the file
    # save_dir = "./raw_animes_dataset/"
    # if not os.path.exists(save_dir):
    #     os.makedirs(save_dir)  # Create the directory if it doesn't exist

    # Save the uploaded file temporarily
    # save_path = os.path.join(save_dir, uploaded_fi
    # le.name)

    with open(uploaded_file.name, "wb") as f:
        f.write(uploaded_file.getbuffer())

    # Read the CSV file into a pandas dataframe
    df = pd.read_csv(uploaded_file)
    
    # Display the uploaded dataset's basic information
    st.subheader("Dataset Information")
    
    # Show the first few rows of the dataset
    st.write("Preview of the dataset:")
    st.write(df.head())
    
    # Show the basic details of the dataset (shape, columns, etc.)
    st.write(f"Number of rows: {df.shape[0]}")
    st.write(f"Number of columns: {df.shape[1]}")
    st.write("Columns in the dataset:")
    st.write(df.columns.tolist())
    
    if st.button("Data Preprocessing"):
        st.write("Please wait.")


        #################################################
        df = df.drop(columns=['anime_id', 'English name', 'Other name', 'Status', 'Licensors', 'Premiered', 'Image URL'])
        df = df[df['Score']!='UNKNOWN']
        df = df[df['Genres']!='UNKNOWN']
        df.loc[(df['Type'] == 'UNKNOWN') | (df['Type'] == 'Unknown'), 'Type'] = 'TV'
        df = df[df['Duration']!='Unknown']
        def convert_to_minutes(time_str):
            total_minutes = 0
            
            # T√¨m t·∫•t c·∫£ c√°c ph·∫ßn gi·ªù, ph√∫t v√† gi√¢y trong chu·ªói
            hours_match = re.search(r'(\d+)\s*hr', time_str)
            minutes_match = re.search(r'(\d+)\s*min', time_str)
            seconds_match = re.search(r'(\d+)\s*sec', time_str)
            
            # Th√™m s·ªë ph√∫t t·ª´ ph·∫ßn 'min'
            if minutes_match:
                total_minutes += int(minutes_match.group(1))
            
            # Th√™m s·ªë ph√∫t t·ª´ ph·∫ßn 'hr' n·∫øu c√≥
            if hours_match:
                total_minutes += int(hours_match.group(1)) * 60
            
            # Th√™m s·ªë ph√∫t t·ª´ ph·∫ßn 'sec' n·∫øu c√≥
            if seconds_match:
                total_minutes += round(int(seconds_match.group(1)) / 60, 2)
            
            return total_minutes

        # √Åp d·ª•ng h√†m chuy·ªÉn ƒë·ªïi cho c·ªôt Duration v√† ƒë·ªïi t√™n c·ªôt
        df['Duration'] = df['Duration'].apply(convert_to_minutes)
        df.rename(columns={'Duration': 'Time per ep (Min)'}, inplace=True)
        df = df[df['Aired'] != 'Not available']
        def preprocess_published(df):
            """
            Preprocesses the 'Published' column in the DataFrame.

            Args:
                df: The DataFrame containing the 'Published' column.

            Returns:
                The DataFrame with 'Released date' and 'Completed date' columns preprocessed.
            """
            def parse_single_date(date_str, is_start_date=True):
                if "," in date_str:
                    parts = date_str.split(",")
                    if len(parts) == 2 and parts[0].isdigit() and len(parts[0].strip()) <= 2:  # "12, 1999"
                        try:
                            month = int(parts[0].strip())
                            year = int(parts[1].strip())
                            if 1 <= month <= 12:  # N·∫øu th√°ng h·ª£p l·ªá
                                return f"{year:04d}-{month:02d}-01"  # Chuy·ªÉn th√†nh "YYYY-MM-DD"
                        except ValueError:
                            pass
                for fmt in ["%b %d, %Y", "%b %Y", "%Y", "%b-%y"]:
                    try:
                        return datetime.strptime(date_str, fmt).strftime("%Y-%m-%d")
                    except ValueError:
                        continue
                return "Unknown" if is_start_date else "Updating"

            def parse_published(published_str):
                if not isinstance(published_str, str) or not published_str.strip():
                    return "Unknown", "Updating"

                published_str = published_str.strip()

                if 'to' in published_str:
                    try:
                        start_date_str, end_date_str = map(str.strip, published_str.split('to'))
                    except ValueError:
                        return "Unknown", "Updating"

                    start_date = parse_single_date(start_date_str, is_start_date=True)
                    end_date = parse_single_date(end_date_str, is_start_date=False)
                    return start_date, end_date
                else:
                    start_date = parse_single_date(published_str, is_start_date=True)
                    return start_date, "Updating"

            # √Åp d·ª•ng h√†m x·ª≠ l√Ω v√† t·∫°o hai c·ªôt m·ªõi
            df['Released date'], df['Completed date'] = zip(*df['Aired'].apply(parse_published))
            return df

        df = preprocess_published(df)
        ### N·∫øu Aired ch·ªâ c√≥ 1 ng√†y duy nh·∫•t, th√¨ Published date v√† Completed date l√† c√πng 1 ng√†y
        def update_completed_date(row):
            """Updates 'Completed date' based on 'Published' and 'Completed date'."""
            if 'to' not in str(row['Aired']) and row['Completed date'] == 'Updating':
                return row['Released date']
            return row['Completed date']

        df['Completed date'] = df.apply(update_completed_date, axis=1)
        df = df.drop(columns=['Aired'])
        df = df.sort_values(by=['Released date'], ascending=[True])

        # Reset l·∫°i index b·∫Øt ƒë·∫ßu t·ª´ 0
        df = df.reset_index(drop=True)

        # Chuy·ªÉn ƒë·ªïi c·ªôt Episodes sang s·ªë (UNKNOWN -> NaN)
        df['Episodes'] = pd.to_numeric(df['Episodes'], errors='coerce')

        # L·ªçc DataFrame ch·ªâ ch·ª©a c√°c d√≤ng c√≥ Type l√† TV
        tv_anime_df = df[df['Type'] == 'TV']

        # Duy·ªát qua t·ª´ng d√≤ng c·ªßa DataFrame g·ªëc
        for idx, value in df['Episodes'].items():
            if pd.isna(value) and df.at[idx, 'Type'] == 'TV':  # N·∫øu Episodes l√† NaN (do UNKNOWN)
                # X√°c ƒë·ªãnh v·ªã tr√≠ d√≤ng t∆∞∆°ng ·ª©ng trong DataFrame TV
                tv_indices = tv_anime_df.index  # Ch·ªâ s·ªë c·ªßa c√°c d√≤ng c√≥ Type l√† TV
                
                # T√¨m v·ªã tr√≠ c·ªßa idx trong danh s√°ch tv_indices
                if idx in tv_indices:
                    position = tv_indices.get_loc(idx)  # V·ªã tr√≠ c·ªßa idx trong danh s√°ch tv_indices
                    
                    # L·∫•y 5 d√≤ng tr∆∞·ªõc v√† 5 d√≤ng sau t·ª´ DataFrame TV
                    start_pos = max(0, position - 5)
                    end_pos = min(len(tv_indices), position + 5 + 1)
                    
                    # L·∫•y gi√° tr·ªã Episodes trong ph·∫°m vi n√†y
                    surrounding_values = df.loc[tv_indices[start_pos:end_pos], 'Episodes'].dropna()
                    
                    # T√¨m gi√° tr·ªã l·ªõn nh·∫•t
                    max_value = surrounding_values.max() if not surrounding_values.empty else None
                    
                    print(f"D√≤ng {idx}: UNKNOWN, max trong ph·∫°m vi [TV d√≤ng {start_pos} ƒë·∫øn {end_pos - 1}] l√† {max_value}")
                    
                    # Thay th·∫ø gi√° tr·ªã UNKNOWN b·∫±ng max_value
                    df.at[idx, 'Episodes'] = max_value
            elif pd.isna(value): 
                df.at[idx, 'Episodes'] = 1

        df = df[df['Rating'] != 'UNKNOWN']

        # Chuy·ªÉn ki·ªÉu d·ªØ li·ªáu:
        df = df.astype({
            'Name': 'object',
            'Score': 'float64',
            'Genres': 'object',
            'Synopsis': 'object',
            'Type': 'object',
            'Episodes': 'float64',
            'Producers': 'object',
            'Studios': 'object',
            'Source': 'object',
            'Time per ep (Min)': 'float64',
            'Rating': 'object',
            'Popularity': 'float64',
            'Favorites': 'float64',
            'Scored By': 'float64',  # "objeect -> int64" typo corrected
            'Members': 'float64',
        })

        df['Released date'] = pd.to_datetime(df['Released date'], errors='coerce').dt.normalize()

        # available_rows = raw_anime_df[raw_anime_df['Rank'] != 'UNKNOWN']

        # Th√™m m·ªôt c·ªôt t·∫°m ƒë·ªÉ ƒë√°nh d·∫•u c√°c gi√° tr·ªã 'UNKNOWN'
        df['Score_numeric'] = pd.to_numeric(df['Score'], errors='coerce')

        # S·∫Øp x·∫øp theo c·ªôt 'Rank_numeric' (gi√° tr·ªã s·ªë tr∆∞·ªõc), sau ƒë√≥ theo c·ªôt 'Rank' g·ªëc ƒë·ªÉ gi·ªØ l·∫°i th·ª© t·ª± ƒë√∫ng
        df = df.sort_values(by=['Score_numeric', 'Score', 'Scored By', 'Name'], ascending=[False, False, False, True])

        # X√≥a c·ªôt t·∫°m
        df = df.drop(columns=['Score_numeric'])

        # T·∫°o th·ª© t·ª± tƒÉng d·∫ßn t·ª´ 1 ƒë·∫øn s·ªë l∆∞·ª£ng d√≤ng
        df['Rank'] = range(1, len(df) + 1)

        # Chuy·ªÉn ki·ªÉu d·ªØ li·ªáu:
        df = df.astype({
            'Name': 'object',
            'Score': 'float64',
            'Genres': 'object',
            'Synopsis': 'object',
            'Type': 'object',
            'Episodes': 'float64',
            'Producers': 'object',
            'Studios': 'object',
            'Source': 'object',
            'Time per ep (Min)': 'float64',
            'Rating': 'object',
            'Popularity': 'int64',
            'Favorites': 'int64',
            'Scored By': 'int64',
            'Members': 'int64',
        })

        df.to_csv("anime-data-preprocessing.csv", sep=',', encoding='utf-8-sig', index=False, header=True)
        #################################################

            
        df = pd.read_csv(r"anime-data-preprocessing.csv")
        st.session_state.csv_file = df.to_csv(index=False)
        
        # Option to download the dataset after preprocessing (if needed)
        st.download_button(
            label="Download preprocessing dataset",
            data=st.session_state.csv_file,
            file_name="anime-data-preprocessing.csv",
            mime="text/csv"
        )

else:
    st.write("No file uploaded yet. Please upload a CSV file to begin.")

